{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Alien_DQN+preprocessing1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4v7ljxG9MDNe",
        "outputId": "024bff00-cadb-46e1-ee09-ecd700f34e55"
      },
      "source": [
        "import numpy as np #for our Qtable\r\n",
        "import gym #for our cartpole Environment\r\n",
        "import random #to generate random numbers\r\n",
        "import pandas\r\n",
        "from collections import deque\r\n",
        "\r\n",
        "#neural network packages\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D,Flatten\r\n",
        "from tensorflow.python.keras import utils\r\n",
        "from tensorflow.keras.optimizers import Adam\r\n",
        "\r\n",
        "#image processing opencv\r\n",
        "import cv2\r\n",
        "\r\n",
        "#code for rendering gui\r\n",
        "!apt-get install python-opengl -y\r\n",
        "!apt install xvfb -y\r\n",
        "!pip install pyvirtualdisplay\r\n",
        "!pip install pyglet==1.4.0\r\n",
        "!apt-get install x11-utils\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from IPython import display as ipythondisplay\r\n",
        "from pyvirtualdisplay import Display\r\n",
        "display = Display(visible=0, size=(1800, 1800))\r\n",
        "display.start()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "Suggested packages:\n",
            "  libgle3\n",
            "The following NEW packages will be installed:\n",
            "  python-opengl\n",
            "0 upgraded, 1 newly installed, 0 to remove and 15 not upgraded.\n",
            "Need to get 496 kB of archives.\n",
            "After this operation, 5,416 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python-opengl all 3.1.0+dfsg-1 [496 kB]\n",
            "Fetched 496 kB in 1s (456 kB/s)\n",
            "Selecting previously unselected package python-opengl.\n",
            "(Reading database ... 146456 files and directories currently installed.)\n",
            "Preparing to unpack .../python-opengl_3.1.0+dfsg-1_all.deb ...\n",
            "Unpacking python-opengl (3.1.0+dfsg-1) ...\n",
            "Setting up python-opengl (3.1.0+dfsg-1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  xvfb\n",
            "0 upgraded, 1 newly installed, 0 to remove and 15 not upgraded.\n",
            "Need to get 784 kB of archives.\n",
            "After this operation, 2,270 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 xvfb amd64 2:1.19.6-1ubuntu4.8 [784 kB]\n",
            "Fetched 784 kB in 1s (660 kB/s)\n",
            "Selecting previously unselected package xvfb.\n",
            "(Reading database ... 148811 files and directories currently installed.)\n",
            "Preparing to unpack .../xvfb_2%3a1.19.6-1ubuntu4.8_amd64.deb ...\n",
            "Unpacking xvfb (2:1.19.6-1ubuntu4.8) ...\n",
            "Setting up xvfb (2:1.19.6-1ubuntu4.8) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Collecting pyvirtualdisplay\n",
            "  Downloading https://files.pythonhosted.org/packages/ad/05/6568620fed440941b704664b9cfe5f836ad699ac7694745e7787fbdc8063/PyVirtualDisplay-2.0-py2.py3-none-any.whl\n",
            "Collecting EasyProcess\n",
            "  Downloading https://files.pythonhosted.org/packages/48/3c/75573613641c90c6d094059ac28adb748560d99bd27ee6f80cce398f404e/EasyProcess-0.3-py2.py3-none-any.whl\n",
            "Installing collected packages: EasyProcess, pyvirtualdisplay\n",
            "Successfully installed EasyProcess-0.3 pyvirtualdisplay-2.0\n",
            "Collecting pyglet==1.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8a/2e/74069cfb668afcb29f0c7777c863d0b1d831accf61558f46cebf34bcfe07/pyglet-1.4.0-py2.py3-none-any.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 8.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet==1.4.0) (0.16.0)\n",
            "Installing collected packages: pyglet\n",
            "  Found existing installation: pyglet 1.5.0\n",
            "    Uninstalling pyglet-1.5.0:\n",
            "      Successfully uninstalled pyglet-1.5.0\n",
            "Successfully installed pyglet-1.4.0\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libxxf86dga1\n",
            "Suggested packages:\n",
            "  mesa-utils\n",
            "The following NEW packages will be installed:\n",
            "  libxxf86dga1 x11-utils\n",
            "0 upgraded, 2 newly installed, 0 to remove and 15 not upgraded.\n",
            "Need to get 209 kB of archives.\n",
            "After this operation, 711 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxxf86dga1 amd64 2:1.1.4-1 [13.7 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11-utils amd64 7.7+3build1 [196 kB]\n",
            "Fetched 209 kB in 1s (220 kB/s)\n",
            "Selecting previously unselected package libxxf86dga1:amd64.\n",
            "(Reading database ... 148818 files and directories currently installed.)\n",
            "Preparing to unpack .../libxxf86dga1_2%3a1.1.4-1_amd64.deb ...\n",
            "Unpacking libxxf86dga1:amd64 (2:1.1.4-1) ...\n",
            "Selecting previously unselected package x11-utils.\n",
            "Preparing to unpack .../x11-utils_7.7+3build1_amd64.deb ...\n",
            "Unpacking x11-utils (7.7+3build1) ...\n",
            "Setting up libxxf86dga1:amd64 (2:1.1.4-1) ...\n",
            "Setting up x11-utils (7.7+3build1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyvirtualdisplay.display.Display at 0x7fcb12541710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gp4VHx3VMI49"
      },
      "source": [
        "class ReplayBuffer():\r\n",
        "  def __init__(self, maxlength, historylength):\r\n",
        "    self.maxlength = maxlength\r\n",
        "    self.historylength = historylength #K number of games screens to stack \r\n",
        "    #previous deque stored <s, a, r, s'>\r\n",
        "    self.action = None  #a[]\r\n",
        "    self.observation = None #s[] + images\r\n",
        "    self.reward = None #r[]\r\n",
        "    self.done = None #d[]\r\n",
        "    self.nextindex =-1\r\n",
        "    self.totalentries =0\r\n",
        "  \r\n",
        "  def getSize(self):\r\n",
        "    return self.totalentries\r\n",
        "\r\n",
        "  def appendFrame(self,state): #add 1 game screen to the observation array\r\n",
        "    if self.observation is None:\r\n",
        "      self.action = np.empty([self.maxlength])\r\n",
        "      self.observation = np.empty([self.maxlength] + list(state.shape),dtype=np.float32)\r\n",
        "      self.reward = np.empty([self.maxlength])\r\n",
        "      self.done = np.empty([self.maxlength])\r\n",
        "\r\n",
        "   \r\n",
        "   \r\n",
        "    self.nextindex = (self.nextindex + 1) % self.maxlength\r\n",
        "    self.observation[self.nextindex] = state\r\n",
        "    self.totalentries = min(self.maxlength, self.totalentries + 1)\r\n",
        "  \r\n",
        "  def appendEffect(self, action, reward,done):#adding action, reward, done\r\n",
        "    self.reward[self.nextindex] = reward\r\n",
        "    self.action[self.nextindex] = action\r\n",
        "    self.done[self.nextindex] = done\r\n",
        "\r\n",
        "  def getBatch(self, idxes): #given the indexed it <retreives stacked s, a, r, stacked s', done>\r\n",
        "    obs_batch      = np.concatenate([self.stackFrames(idx)[np.newaxis, :] for idx in idxes], axis=0)\r\n",
        "    act_batch      = self.action[idxes]\r\n",
        "    rew_batch      = self.reward[idxes]\r\n",
        "    next_obs_batch = np.concatenate([self.stackFrames(idx + 1)[np.newaxis, :] for idx in idxes], axis=0)\r\n",
        "    done_batch      = self.done[idxes]\r\n",
        "    return obs_batch, act_batch, rew_batch, next_obs_batch, done_batch\r\n",
        "\r\n",
        "  def sample(self, batch_size):\r\n",
        "    idxes=random.sample(range(0, self.totalentries-2), batch_size)\r\n",
        "    return self.getBatch(idxes)\r\n",
        "\r\n",
        "  def get_recent_state(self):#previous k frames for the most recent state\r\n",
        "    return self.stackFrames((self.nextindex-1) % self.maxlength)\r\n",
        "  \r\n",
        "\r\n",
        "  def stackFrames(self,idx): #given an index idx, it needs to return a stack of image screens from idx-k to idx\r\n",
        "    end_idx   = idx + 1 # make noninclusive\r\n",
        "    start_idx = end_idx - self.historylength\r\n",
        "    \r\n",
        "    #low dimensional observations\r\n",
        "    if len(self.observation.shape) == 2:\r\n",
        "        return self.observation[end_idx-1]\r\n",
        "\r\n",
        "    # insufficient frames in buffer\r\n",
        "    if start_idx < 0 and self.totalentries != self.maxlength:\r\n",
        "        start_idx = 0\r\n",
        "    for idx in range(start_idx, end_idx - 1):\r\n",
        "        if self.done[idx % self.maxlength]:\r\n",
        "            start_idx = idx + 1\r\n",
        "            \r\n",
        "    #fill the missing history frames with zeros\r\n",
        "    missing_context = self.historylength - (end_idx - start_idx)\r\n",
        "    if start_idx < 0 or missing_context > 0:\r\n",
        "        frames = [np.zeros_like(self.observation[0]) for _ in range(missing_context)]\r\n",
        "        for idx in range(start_idx, end_idx):\r\n",
        "            frames.append(self.observation[idx % self.maxlength])\r\n",
        "        return np.concatenate(frames,2)\r\n",
        "    else:\r\n",
        "        img_h, img_w = self.observation.shape[1], self.observation.shape[2]\r\n",
        "        return self.observation[start_idx:end_idx].reshape(img_h, img_w,-1)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mV-NTwLrML6M"
      },
      "source": [
        "class DQN():\r\n",
        "  def __init__(self,state_space,action_space,weights_file):\r\n",
        "    self.learning_rate = 0.2          # Learning rate\r\n",
        "    self.gamma = 0.95                 # Discounting rate\r\n",
        "\r\n",
        "    # Exploration parameters\r\n",
        "    self.epsilon = 0.99                 # Exploration rate\r\n",
        "    self.max_epsilon = 0.99             # Exploration probability at start\r\n",
        "    self.min_epsilon = 0.1            # Minimum exploration probability \r\n",
        "    self.decay_rate = 0.995            # Exponential decay rate for exploration prob\r\n",
        "\r\n",
        "    #neural network parameters\r\n",
        "    self.state_space = state_space\r\n",
        "    self.action_space=action_space\r\n",
        "    self.batch_size =16\r\n",
        "    self.input_size = state_space.shape\r\n",
        "    self.output_size = action_space.n\r\n",
        "    self.model = self.buildQNetwork()\r\n",
        "    self.target = self.buildQNetwork()\r\n",
        "    #self.memory = deque(maxlen=2000)  #doubel ended queue for storing the transitions\r\n",
        "    self.historylength=4\r\n",
        "    self.memory = ReplayBuffer(2000,self.historylength)\r\n",
        "    self.target_update_interval = 4\r\n",
        "    self.weights_file = weights_file\r\n",
        "    self.image_width =84\r\n",
        "    self.image_height =84\r\n",
        "\r\n",
        "  def resetBuffer(self):\r\n",
        "    self.memory = ReplayBuffer(2000,self.historylength)\r\n",
        "\r\n",
        "  def addFrame(self, state):\r\n",
        "    self.memory.appendFrame(state)\r\n",
        "\r\n",
        "  def addEffect(self, action, reward, done):\r\n",
        "    self.memory.appendEffect(action, reward, done)\r\n",
        "  \r\n",
        "  def getRecentState(self):\r\n",
        "    return self.memory.get_recent_state()\r\n",
        "\r\n",
        "\r\n",
        "  def updateTarget(self,steps):\r\n",
        "    if self.memory.getSize() >= 2*self.batch_size and steps % self.target_update_interval == 0:\r\n",
        "      self.target.set_weights(self.model.get_weights())\r\n",
        "      print(\"target updated\")\r\n",
        "\r\n",
        "  def load_weights(self):\r\n",
        "    self.model.load_weights(self.weights_file)\r\n",
        "\r\n",
        "  def save_weights(self):\r\n",
        "    print(\"Saving wights to file\")\r\n",
        "    self.model.save_weights(self.weights_file)\r\n",
        "\r\n",
        "  def preprocess(self,image):\r\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\r\n",
        "\r\n",
        "    image = cv2.resize(image, (self.image_width, self.image_height), interpolation=cv2.INTER_AREA)\r\n",
        "   \r\n",
        "    return  np.reshape(image,(self.image_width, self.image_height,1))\r\n",
        "  \r\n",
        "  \r\n",
        "  def buildQNetwork(self):\r\n",
        "    model = Sequential()\r\n",
        "    model.add(Conv2D(32, (3,3), input_shape=(84,84,4), activation='relu'))\r\n",
        "    model.add(MaxPool2D(pool_size=(2,2)))\r\n",
        "    model.add(Conv2D(64, (3,3),activation='relu'))\r\n",
        "    model.add(MaxPool2D(pool_size=(2,2)))\r\n",
        "    model.add(Flatten())\r\n",
        "    model.add(Dense(10, activation='relu'))#fully connected\r\n",
        "    model.add(Dense(10, activation='relu'))\r\n",
        "    model.add(Dense(self.output_size))\r\n",
        "    model.compile(loss='mse', optimizer=Adam(lr=0.0001, clipvalue=1))\r\n",
        "    return model\r\n",
        "\r\n",
        "  def predict(self, state, isTarget):\r\n",
        "    state = np.reshape(state, (1,) + state.shape)\r\n",
        "    state = tf.cast(state,dtype=tf.float32)\r\n",
        "    if isTarget:\r\n",
        "      result= self.target.predict(state)\r\n",
        "    else:\r\n",
        "      result= self.model.predict(state)\r\n",
        "    #print(result.shape)\r\n",
        "    return result\r\n",
        "\r\n",
        "    \r\n",
        "  def chooseAction(self,state,isEpsilonGreedy):\r\n",
        "    exp_exp_tradeoff = random.uniform(0, 1)\r\n",
        "    \r\n",
        "    if exp_exp_tradeoff > self.epsilon or not isEpsilonGreedy:\r\n",
        "        qval = self.predict(state,False)[0]\r\n",
        "        maxqval = max(qval)\r\n",
        "        action= np.where(qval == maxqval)[0][0]\r\n",
        "        print(\"Qaction\",action)\r\n",
        "       \r\n",
        "    else:\r\n",
        "        action = self.action_space.sample()\r\n",
        "        print(\"random action\",action)\r\n",
        "    return action\r\n",
        "\r\n",
        "  def updateEpsilon(self,steps):\r\n",
        "    self.epsilon *= self.decay_rate\r\n",
        "    if(self.epsilon < self.min_epsilon):\r\n",
        "      self.epsilon = self.min_epsilon\r\n",
        "    #print(self.epsilon)\r\n",
        "    #self.epsilon = self.min_epsilon + (self.max_epsilon - self.min_epsilon)*np.exp(-self.decay_rate*steps) \r\n",
        "\r\n",
        "  def calcualteTargetValue(self,state, action, reward, next_state, isDone):\r\n",
        "    \r\n",
        "    \r\n",
        "    qnext = self.predict(next_state, True)\r\n",
        "    maxqval = max(qnext[0])\r\n",
        "   \r\n",
        "    if done:\r\n",
        "      target_value = reward\r\n",
        "    else:\r\n",
        "      target_value = reward + self.gamma *maxqval \r\n",
        "\r\n",
        "    return target_value\r\n",
        "\r\n",
        "  def train(self):\r\n",
        "    X_train = np.zeros((self.batch_size,self.image_width,self.image_height,self.historylength))\r\n",
        "    Y_train = np.zeros((self.batch_size, self.output_size))\r\n",
        "    loss =0\r\n",
        "    if self.memory.getSize()< 2*self.batch_size:\r\n",
        "      print(\"memory insufficient for training\")\r\n",
        "      return loss\r\n",
        "\r\n",
        "    state_batch, act_batch, rew_batch, next_state_batch, done_batch = self.memory.sample(self.batch_size)\r\n",
        "    for index_rep in range(self.batch_size):\r\n",
        "      X_train[index_rep] = state_batch[index_rep]\r\n",
        "      Y_train[index_rep][action] = self.calcualteTargetValue(state_batch[index_rep],act_batch[index_rep],rew_batch[index_rep],next_state_batch[index_rep],done_batch[index_rep])\r\n",
        "    #print(\"train shape\",X_train.shape,\"yshape\",Y_train.shape)\r\n",
        "    loss = self.model.train_on_batch(X_train, Y_train)\r\n",
        "    \r\n",
        "    return loss\r\n",
        "\r\n",
        "\r\n",
        "env = gym.make(\"Alien-v0\")\r\n",
        "#print(env.observation_space,env.observation_space.shape)\r\n",
        "#print(env.action_space)\r\n",
        "rewards = []\r\n",
        "weights_file = 'dqn.h5'\r\n",
        "learner = DQN(env.observation_space,env.action_space,weights_file)\r\n",
        "total_episodes = 2      # Total episodes\r\n",
        "max_steps = 50              # Max steps per episode\r\n",
        "total_steps=0"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "id": "e-xdduGqMQaZ",
        "outputId": "35a30dbd-4113-4de1-ad8a-3c3bec3295d2"
      },
      "source": [
        "env = gym.make(\"Alien-v0\")\r\n",
        "#print(env.observation_space,env.observation_space.shape)\r\n",
        "#print(env.action_space)\r\n",
        "rewards = []\r\n",
        "weights_file = 'dqn.h5'\r\n",
        "learner = DQN(env.observation_space,env.action_space,weights_file)\r\n",
        "total_episodes = 2      # Total episodes\r\n",
        "max_steps = 50              # Max steps per episode\r\n",
        "total_steps=0\r\n",
        "skipFrames = 3\r\n",
        "for episode in range(total_episodes): \r\n",
        "    # Reset the environment\r\n",
        "    state = env.reset()\r\n",
        "    \r\n",
        "\r\n",
        "    step = 0\r\n",
        "    done = False\r\n",
        "    total_rewards = 0\r\n",
        "    loss =0\r\n",
        "    prev_screen = env.render(mode='rgb_array')\r\n",
        "    plt.imshow(prev_screen)\r\n",
        "    for step in range(max_steps): \r\n",
        "      screen = env.render(mode='rgb_array')\r\n",
        "      plt.imshow(screen)\r\n",
        "      ipythondisplay.clear_output(wait=True)\r\n",
        "      ipythondisplay.display(plt.gcf())\r\n",
        "      \r\n",
        "      if(total_steps % skipFrames == 0):\r\n",
        "        state = learner.preprocess(state)\r\n",
        "        learner.addFrame(state)\r\n",
        "      action = learner.chooseAction(learner.getRecentState(),True)\r\n",
        "      # Take the action (a) and observe the outcome state(s') and reward (r)\r\n",
        "      new_state, reward, done, info = env.step(action)\r\n",
        "\r\n",
        "      if(total_steps % skipFrames == 0):\r\n",
        "        learner.addEffect(action,reward,done)\r\n",
        "      #Calcualte the loss and train (optimize) the Q-network\r\n",
        "      \r\n",
        "      #print(total_steps,total_steps % skipFrames, int(total_steps/skipFrames))\r\n",
        "      if(total_steps % skipFrames == 0):\r\n",
        "        print(\"updating Q-network\")\r\n",
        "        loss +=learner.train()\r\n",
        "      \r\n",
        "      learner.updateTarget(int(total_steps/skipFrames))\r\n",
        "\r\n",
        "      total_rewards += reward\r\n",
        "      total_steps += 1\r\n",
        "      # Our new state is state\r\n",
        "      state = new_state\r\n",
        "      \r\n",
        "      # If done (if we're dead) : finish episode\r\n",
        "      if done == True:\r\n",
        "        print(\"game over\")\r\n",
        "        break\r\n",
        "  # Reduce epsilon (because we need less and less exploration)\r\n",
        "      learner.updateEpsilon(total_steps)\r\n",
        "    print(\"loss=\",loss)\r\n",
        "    rewards.append(total_rewards)\r\n",
        "    ipythondisplay.clear_output(wait=True)\r\n",
        "print(rewards, max(rewards))\r\n",
        "print (\"Score over time: \" +  str(sum(rewards)/total_episodes))\r\n",
        "learner.save_weights()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}